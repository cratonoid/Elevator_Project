{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd609cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mylib.centroidtracker import CentroidTracker\n",
    "from mylib.trackableobject import TrackableObject\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from mylib.mailer import Mailer\n",
    "from mylib import config, thread\n",
    "from sklearnex import patch_sklearn\n",
    "import time, schedule, csv\n",
    "import numpy as np\n",
    "import argparse, imutils\n",
    "import time, dlib, cv2, datetime\n",
    "from itertools import zip_longest\n",
    "patch_sklearn()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "def run():\n",
    "    prototxt='mobilenet_ssd/MobileNetSSD_deploy.prototxt'\n",
    "    model='mobilenet_ssd/MobileNetSSD_deploy.caffemodel'    \n",
    "    # construct the argument parse and parse the arguments\n",
    "    args= {'prototxt': 'mobilenet_ssd/MobileNetSSD_deploy.prototxt', \"model\":\"mobilenet_ssd/MobileNetSSD_deploy.caffemodel\", 'input': 'videos/VIDEO.mp4', 'output': None, 'confidence': 0.4, 'skip_frames': 30}\n",
    "    # initialize the list of class labels MobileNet SSD was trained to\n",
    "    # detect\n",
    "    CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "        \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "        \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "        \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    # load our serialized model from disk\n",
    "    net = cv2.dnn.readNetFromCaffe(prototxt,model)\n",
    "    # if a video path was not supplied, grab a reference to the ip camera\n",
    "    if not args.get(\"input\", False):\n",
    "        print(\"[INFO] Starting the live stream..\")\n",
    "        vs = VideoStream(config.url).start()\n",
    "        time.sleep(2.0)\n",
    "    # otherwise, grab a reference to the video file\n",
    "    else:\n",
    "        print(\"[INFO] Starting the video..\")\n",
    "        vs = cv2.VideoCapture(args[\"input\"])\n",
    "    # initialize the video writer (we'll instantiate later if need be)\n",
    "    writer = None\n",
    "    # initialize the frame dimensions (we'll set them as soon as we read\n",
    "    # the first frame from the video)\n",
    "    W = None\n",
    "    H = None\n",
    "    # instantiate our centroid tracker, then initialize a list to store\n",
    "    # each of our dlib correlation trackers, followed by a dictionary to\n",
    "    # map each unique object ID to a TrackableObject\n",
    "    ct = CentroidTracker(maxDisappeared=40, maxDistance=50)\n",
    "    trackers = []\n",
    "    trackableObjects = {}\n",
    "    # initialize the total number of frames processed thus far, along\n",
    "    # with the total number of objects that have moved either up or down\n",
    "    totalFrames = 0\n",
    "    totalDown = 0\n",
    "    totalUp = 0\n",
    "    x = []\n",
    "    empty=[]\n",
    "    empty1=[]\n",
    "    # start the frames per second throughput estimator\n",
    "    fps = FPS().start()\n",
    "    if config.Thread:\n",
    "        vs = thread.ThreadingClass(config.url)\n",
    "    # loop over frames from the video stream\n",
    "    while True:\n",
    "        # grab the next frame and handle if we are reading from either\n",
    "        # VideoCapture or VideoStream\n",
    "        frame = vs.read()\n",
    "        frame = frame[1] if args.get(\"input\", False) else frame\n",
    "        # if we are viewing a video and we did not grab a frame then we\n",
    "        # have reached the end of the video\n",
    "        if args[\"input\"] is not None and frame is None:\n",
    "            break\n",
    "        # resize the frame to have a maximum width of 500 pixels (the\n",
    "        # less data we have, the faster we can process it), then convert\n",
    "        # the frame from BGR to RGB for dlib\n",
    "        frame = imutils.resize(frame, width = 500)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # if the frame dimensions are empty, set them\n",
    "        if W is None or H is None:\n",
    "            (H, W) = frame.shape[:2]\n",
    "        # if we are supposed to be writing a video to disk, initialize\n",
    "        # the writer\n",
    "        if args[\"output\"] is not None and writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            writer = cv2.VideoWriter(args[\"output\"], fourcc, 30,\n",
    "                (W, H), True)\n",
    "        # initialize the current status along with our list of bounding\n",
    "        # box rectangles returned by either (1) our object detector or\n",
    "        # (2) the correlation trackers\n",
    "        status = \"Waiting\"\n",
    "        rects = []\n",
    "        # check to see if we should run a more computationally expensive\n",
    "        # object detection method to aid our tracker\n",
    "        if totalFrames % args[\"skip_frames\"] == 0:\n",
    "            # set the status and initialize our new set of object trackers\n",
    "            status = \"Detecting\"\n",
    "            trackers = []\n",
    "            # convert the frame to a blob and pass the blob through the\n",
    "            # network and obtain the detections\n",
    "            blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "            # loop over the detections\n",
    "            for i in np.arange(0, detections.shape[2]):\n",
    "                # extract the confidence (i.e., probability) associated\n",
    "                # with the prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                # filter out weak detections by requiring a minimum\n",
    "                # confidence\n",
    "                if confidence > args[\"confidence\"]:\n",
    "                    # extract the index of the class label from the\n",
    "                    # detections list\n",
    "                    idx = int(detections[0, 0, i, 1])\n",
    "                    # if the class label is not a person, ignore it\n",
    "                    if CLASSES[idx] != \"person\":\n",
    "                        continue\n",
    "                    # compute the (x, y)-coordinates of the bounding box\n",
    "                    # for the object\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    # construct a dlib rectangle object from the bounding\n",
    "                    # box coordinates and then start the dlib correlation\n",
    "                    # tracker\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "                    tracker.start_track(rgb, rect)\n",
    "                    # add the tracker to our list of trackers so we can\n",
    "                    # utilize it during skip frames\n",
    "                    trackers.append(tracker)\n",
    "        # otherwise, we should utilize our object *trackers* rather than\n",
    "        # object *detectors* to obtain a higher frame processing throughput\n",
    "        else:\n",
    "            # loop over the trackers\n",
    "            for tracker in trackers:\n",
    "                # set the status of our system to be 'tracking' rather\n",
    "                # than 'waiting' or 'detecting'\n",
    "                status = \"Tracking\"\n",
    "                # update the tracker and grab the updated position\n",
    "                tracker.update(rgb)\n",
    "                pos = tracker.get_position()\n",
    "                # unpack the position object\n",
    "                startX = int(pos.left())\n",
    "                startY = int(pos.top())\n",
    "                endX = int(pos.right())\n",
    "                endY = int(pos.bottom())\n",
    "                # add the bounding box coordinates to the rectangles list\n",
    "                rects.append((startX, startY, endX, endY))\n",
    "        # draw a horizontal line in the center of the frame -- once an\n",
    "        # object crosses this line we will determine whether they were\n",
    "        # moving 'up' or 'down'\n",
    "        cv2.line(frame, (0, H // 2), (W, H // 2), (0, 0, 0), 3)\n",
    "        cv2.putText(frame, \"-Prediction border - Entrance-\", (10, H - ((i * 20) + 200)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "        # use the centroid tracker to associate the (1) old object\n",
    "        # centroids with (2) the newly computed object centroids\n",
    "        objects = ct.update(rects)\n",
    "        # loop over the tracked objects\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            # check to see if a trackable object exists for the current\n",
    "            # object ID\n",
    "            to = trackableObjects.get(objectID, None)\n",
    "            # if there is no existing trackable object, create one\n",
    "            if to is None:\n",
    "                to = TrackableObject(objectID, centroid)\n",
    "            # otherwise, there is a trackable object so we can utilize it\n",
    "            # to determine direction\n",
    "            else:\n",
    "                # the difference between the y-coordinate of the *current*\n",
    "                # centroid and the mean of *previous* centroids will tell\n",
    "                # us in which direction the object is moving (negative for\n",
    "                # 'up' and positive for 'down')\n",
    "                y = [c[1] for c in to.centroids]\n",
    "                direction = centroid[1] - np.mean(y)\n",
    "                to.centroids.append(centroid)\n",
    "                # check to see if the object has been counted or not\n",
    "                if not to.counted:\n",
    "                    # if the direction is negative (indicating the object\n",
    "                    # is moving up) AND the centroid is above the center\n",
    "                    # line, count the object\n",
    "                    if direction < 0 and centroid[1] < H // 2:\n",
    "                        totalUp += 1\n",
    "                        empty.append(totalUp)\n",
    "                        to.counted = True\n",
    "                    # if the direction is positive (indicating the object\n",
    "                    # is moving down) AND the centroid is below the\n",
    "                    # center line, count the object\n",
    "                    elif direction > 0 and centroid[1] > H // 2:\n",
    "                        totalDown += 1\n",
    "                        empty1.append(totalDown)\n",
    "                        #print(empty1[-1])\n",
    "                        # if the people limit exceeds over threshold, send an email alert\n",
    "                        if sum(x) >= config.Threshold:\n",
    "                            cv2.putText(frame, \"-ALERT: People limit exceeded-\", (10, frame.shape[0] - 80),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                            if config.ALERT:\n",
    "                                print(\"[INFO] Sending email alert..\")\n",
    "                                Mailer().send(config.MAIL)\n",
    "                                print(\"[INFO] Alert sent\")\n",
    "                        to.counted = True\n",
    "                    x = []\n",
    "                    # compute the sum of total people inside\n",
    "                    x.append(len(empty1)-len(empty))\n",
    "                    #print(\"Total people inside:\", x)\n",
    "            # store the trackable object in our dictionary\n",
    "            trackableObjects[objectID] = to\n",
    "            # draw both the ID of the object and the centroid of the\n",
    "            # object on the output frame\n",
    "            text = \"ID {}\".format(objectID)\n",
    "            cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.circle(frame, (centroid[0], centroid[1]), 4, (255, 255, 255), -1)\n",
    "        # construct a tuple of information we will be displaying on the\n",
    "        info = [\n",
    "        (\"Exit\", totalUp),\n",
    "        (\"Enter\", totalDown),\n",
    "        (\"Status\", status),\n",
    "        ]\n",
    "        info2 = [\n",
    "        (\"Total people inside\", x),\n",
    "        ]\n",
    "                # Display the output\n",
    "        for (i, (k, v)) in enumerate(info):\n",
    "            text = \"{}: {}\".format(k, v)\n",
    "            cv2.putText(frame, text, (10, H - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        for (i, (k, v)) in enumerate(info2):\n",
    "            text = \"{}: {}\".format(k, v)\n",
    "            cv2.putText(frame, text, (265, H - ((i * 20) + 60)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        # Initiate a simple log to save data at end of the day\n",
    "        if config.Log:\n",
    "            datetimee = [datetime.datetime.now()]\n",
    "            d = [datetimee, empty1, empty, x]\n",
    "            export_data = zip_longest(*d, fillvalue = '')\n",
    "            with open('Log.csv', 'w', newline='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow((\"End Time\", \"In\", \"Out\", \"Total Inside\"))\n",
    "                wr.writerows(export_data)\n",
    "        # check to see if we should write the frame to disk\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Real-Time Monitoring/Analysis Window\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        # increment the total number of frames processed thus far and\n",
    "        # then update the FPS counter\n",
    "        totalFrames += 1\n",
    "        fps.update()\n",
    "        if config.Timer:\n",
    "            # Automatic timer to stop the live stream. Set to 8 hours (28800s).\n",
    "            t1 = time.time()\n",
    "            num_seconds=(t1-t0)\n",
    "            if num_seconds > 28800:\n",
    "                break\n",
    "    # stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "    # # if we are not using a video file, stop the camera video stream\n",
    "    # if not args.get(\"input\", False):\n",
    "    # \tvs.stop()\n",
    "    #\n",
    "    # # otherwise, release the video file pointer\n",
    "    # else:\n",
    "    # \tvs.release()\n",
    "    # issue 15\n",
    "    if config.Thread:\n",
    "        vs.release()\n",
    "    # close any open windows\n",
    "    cv2.destroyAllWindows()\n",
    "##learn more about different schedules here: https://pypi.org/project/schedule/\n",
    "if config.Scheduler:\n",
    "    ##Runs for every 1 second\n",
    "    #schedule.every(1).seconds.do(run)\n",
    "    ##Runs at every day (09:00 am). You can change it.\n",
    "    schedule.every().day.at(\"09:00\").do(run)\n",
    "    while 1:\n",
    "        schedule.run_pending()\n",
    "else:\n",
    "\trun()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (OpenVINO 2021.4.2)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
